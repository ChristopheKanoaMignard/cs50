# PageRank

This is a rudimentary implementation of a PageRank algorithm that ranks the importance of a webpage based on how often it is linked to by other pages. Two models are used: the first is by sampling pages from a Markov Chain random surfer and the second by iteratively applying a PageRank formula.

Both models were checked manually by me and automatically by check50. There is an insignificant math error for the iterative model when at least one page has no links. The result for one of the pages should be in the range [0.23978, 0.24378] but I got 0.23973. Under all other tested coniditions, both models work as expected.
## Sampling Model
Conisder a random surfer who starts on a random web page, then clicks a random link on the current page with a probability of $d$; or else with a probabilty of $1-d$, the surfer jumps to an unlinked webpage (including the current page). We can assign a PageRank value to each web page by sampling many time, we chose 10,000, and assigning a page's PageRank value equal to the propotion of times a page was visited. 

## Iterative Model
We can instead define a page’s PageRank using a recursive mathematical expression. For a given page, p, let $PR(p)$ be the PageRank: the probability that a random surfer ends up on that page. A random surfer can end up on a page with probability $1-d$ by randomly jumping or with probability $d$ by following a link from page i to page p. 

The first condition can simply be expressed as $\frac{1-d}{N}$ where $N$ is the total number of pages across the corpus, since the $1-d$ probability of choosing a page at random is evenly split among $N$ possible pages. 

For the second condition, we need to consider each possible page i that links to page p. For each of those incoming pages, let $NumLinks(i)$ be the number of links on page i. Each page i that links to p has its own PageRank, $PR(i)$, representing the probability that we are on page i at any given time. And since from page i we travel to any of that page’s links with equal probability, we divide $PR(i)$ by the number of links $NumLinks(i)$ to get the probability that we were on page i and chose the link to page p. 

This gives us the following formula for the PageRank for a page p.

$$PR(p) = \frac{1-d}{N} + d \sum_i \frac{PR(i)}{NumLinks(i)}$$


# Functions
Below are descriptions of the functions I created. 

## transition_model
The transition_model returns a dictionary representing the probability distribution over which page a random surfer would visit next, given a corpus of pages, a current page, and a damping factor.

* The function accepts three arguments: corpus, page, and damping_factor.
  - The corpus is a Python dictionary mapping a page name to a set of all pages linked to by that page.
  - The page is a string representing which page the random surfer is currently on.
  - The damping_factor is a floating point number representing the damping factor to be used when generating the probabilities.
* The return value of the function is a Python dictionary with one key for each page in the corpus and a value representing the probability that a random surfer would choose that page next.
  - With probability damping_factor, the random surfer should randomly choose one of the links from page with equal probability.
  - With probability 1 - damping_factor, the random surfer should randomly choose one of all pages in the corpus with equal probability.
* If page has no outgoing links, then transition_model returns a probability distribution that chooses randomly among all pages with equal probability. (In other words, if a page has no links, we can pretend it has links to all pages in the corpus, including itself.)

## sample_pagerank
The sample_pagerank function accepts a corpus of web pages, a damping factor, and a number of samples, and return an estimated PageRank for each page.

* The function accepts three arguments: corpus, a damping_factor, and n.
  - The corpus is a Python dictionary mapping a page name to a set of all pages linked to by that page.
  - The damping_factor is a floating point number representing the damping factor to be used by the transition model.
  - n is an integer representing the number of samples that should be generated to estimate PageRank values.
* The return value of the function is a Python dictionary with one key for each page in the corpus with a value representing that page’s estimated PageRank (i.e., the proportion of all the samples that corresponded to that page).
* The first sample is generated by choosing from a page at random. For each of the remaining samples, the next sample should be generated from the previous sample based on the previous sample’s transition model.

## iterate_pagerank
The iterate_pagerank function should accept a corpus of web pages and a damping factor, calculate PageRanks based on the iteration formula described above, and return each page’s PageRank accurate to within 0.001.

* The function accepts two arguments: corpus and damping_factor.
  - The corpus is a Python dictionary mapping a page name to a set of all pages linked to by that page.
  - The damping_factor is a floating point number representing the damping factor to be used in the PageRank formula.
  - The return value of the function is a Python dictionary with one key for each page in the corpus wtih a value representing that page’s PageRank. 
* The function begins by assigning each page a rank of 1 / N, where N is the total number of pages in the corpus. Then it repeatedly calculates new rank values based on all of the current rank values, according to the PageRank formula.
  - A page that has no links at all gets interpreted as having one link for every page in the corpus (including itself).
  - This process repeats until no PageRank value changes by more than 0.001 between the current rank values and the new rank values.
